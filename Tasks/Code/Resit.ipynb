{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09a83e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "from rdflib import URIRef, BNode, Literal\n",
    "from rdflib import Namespace\n",
    "from rdflib.namespace import OWL, RDF, RDFS, FOAF, XSD\n",
    "from rdflib.util import guess_format\n",
    "from isub import isub\n",
    "import csv\n",
    "import owlrl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "488f8c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"IN3067-INM713_coursework_data_pizza_500.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62c8079b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(501, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "185ca7f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>categories</th>\n",
       "      <th>menu item</th>\n",
       "      <th>item value</th>\n",
       "      <th>currency</th>\n",
       "      <th>item description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Little Pizza Paradise</td>\n",
       "      <td>Cascade Village Mall Across From Target</td>\n",
       "      <td>Bend</td>\n",
       "      <td>US</td>\n",
       "      <td>97701.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>Pizza Place</td>\n",
       "      <td>Bianca Pizza</td>\n",
       "      <td>22.50</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Little Pizza Paradise</td>\n",
       "      <td>Cascade Village Mall Across From Target</td>\n",
       "      <td>Bend</td>\n",
       "      <td>US</td>\n",
       "      <td>97701.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>Pizza Place</td>\n",
       "      <td>Cheese Pizza</td>\n",
       "      <td>18.95</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Brentwood</td>\n",
       "      <td>148 S Barrington Ave</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>US</td>\n",
       "      <td>90049.0</td>\n",
       "      <td>Brentwood</td>\n",
       "      <td>American Restaurant,Bar,Bakery</td>\n",
       "      <td>Pizza, Margherita</td>\n",
       "      <td>12.00</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Brentwood</td>\n",
       "      <td>148 S Barrington Ave</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>US</td>\n",
       "      <td>90049.0</td>\n",
       "      <td>Brentwood</td>\n",
       "      <td>American Restaurant,Bar,Bakery</td>\n",
       "      <td>Pizza, Mushroom</td>\n",
       "      <td>13.00</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Brentwood</td>\n",
       "      <td>148 S Barrington Ave</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>US</td>\n",
       "      <td>90049.0</td>\n",
       "      <td>Brentwood</td>\n",
       "      <td>American Restaurant,Bar,Bakery</td>\n",
       "      <td>Pizza, Puttenesca</td>\n",
       "      <td>13.00</td>\n",
       "      <td>USD</td>\n",
       "      <td>Olives, onions, capers, tomatoes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name                                  address  \\\n",
       "0  Little Pizza Paradise  Cascade Village Mall Across From Target   \n",
       "1  Little Pizza Paradise  Cascade Village Mall Across From Target   \n",
       "2          The Brentwood                     148 S Barrington Ave   \n",
       "3          The Brentwood                     148 S Barrington Ave   \n",
       "4          The Brentwood                     148 S Barrington Ave   \n",
       "\n",
       "          city country  postcode      state                      categories  \\\n",
       "0         Bend      US   97701.0         OR                     Pizza Place   \n",
       "1         Bend      US   97701.0         OR                     Pizza Place   \n",
       "2  Los Angeles      US   90049.0  Brentwood  American Restaurant,Bar,Bakery   \n",
       "3  Los Angeles      US   90049.0  Brentwood  American Restaurant,Bar,Bakery   \n",
       "4  Los Angeles      US   90049.0  Brentwood  American Restaurant,Bar,Bakery   \n",
       "\n",
       "           menu item  item value currency                  item description  \n",
       "0       Bianca Pizza       22.50      USD                               NaN  \n",
       "1       Cheese Pizza       18.95      USD                               NaN  \n",
       "2  Pizza, Margherita       12.00      USD                               NaN  \n",
       "3    Pizza, Mushroom       13.00      USD                               NaN  \n",
       "4  Pizza, Puttenesca       13.00      USD  Olives, onions, capers, tomatoes  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d4136df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.country.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5a3f6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                  0\n",
      "address               0\n",
      "city                  0\n",
      "country               0\n",
      "postcode             10\n",
      "state                 0\n",
      "categories            0\n",
      "menu item             0\n",
      "item value           78\n",
      "currency             75\n",
      "item description    325\n",
      "dtype: int64\n",
      "name                 object\n",
      "address              object\n",
      "city                 object\n",
      "country              object\n",
      "postcode            float64\n",
      "state                object\n",
      "categories           object\n",
      "menu item            object\n",
      "item value          float64\n",
      "currency             object\n",
      "item description     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b9e647",
   "metadata": {},
   "source": [
    "### Subtask RDF.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1ea5f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faiqh\\AppData\\Local\\Temp\\ipykernel_17976\\758250120.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(new_entries, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# here we create 2 random restaurants and will append them to the dataframe\n",
    "\n",
    "cols = ['name','address','city','country','postcode','state','categories','menu item','item value','currency','item description']\n",
    "new_entries = pd.DataFrame([\n",
    "  ['Restaurant A', '123 Main St', 'Springfield', 'US', '12345', 'IL', \n",
    "   'Pizza Place', 'Margherita Pizza', 12.5, 'USD', None],\n",
    "\n",
    "  ['Restaurant B', '467 Main St', 'Providence', 'US', '90210', 'RI',\n",
    "   'Pizza Place','Pepperoni Pizza', 15.0, 'USD', None]\n",
    "], columns=cols)\n",
    "\n",
    "df = df.append(new_entries, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d958194a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             name      address         city country postcode state  \\\n",
      "501  Restaurant A  123 Main St  Springfield      US    12345    IL   \n",
      "502  Restaurant B  467 Main St   Providence      US    90210    RI   \n",
      "\n",
      "      categories         menu item  item value currency item description  \n",
      "501  Pizza Place  Margherita Pizza        12.5      USD             None  \n",
      "502  Pizza Place   Pepperoni Pizza        15.0      USD             None  \n"
     ]
    }
   ],
   "source": [
    "# Filter rows where 'restaurant_name' is 'Restaurant A' or 'Restaurant B'\n",
    "mask = df['name'].isin(['Restaurant A', 'Restaurant B'])\n",
    "filtered_df = df[mask]\n",
    "\n",
    "# Print all rows where 'restaurant_name' is 'Restaurant A' or 'Restaurant B'\n",
    "print(filtered_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19b16c29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                 object\n",
      "address              object\n",
      "city                 object\n",
      "country              object\n",
      "postcode             object\n",
      "state                object\n",
      "categories           object\n",
      "menu item            object\n",
      "item value          float64\n",
      "currency             object\n",
      "item description     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95442d2",
   "metadata": {},
   "source": [
    "The names of the states are not uniform, some are abbreviated while some have their full names, so we will create a dictionary so that the abbreviations are linked with their full names. Once that's done, we will then standardize the data by displaying the names of the states with their full name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f749c170",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>categories</th>\n",
       "      <th>menu item</th>\n",
       "      <th>item value</th>\n",
       "      <th>currency</th>\n",
       "      <th>item description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Little Pizza Paradise</td>\n",
       "      <td>Cascade Village Mall Across From Target</td>\n",
       "      <td>Bend</td>\n",
       "      <td>US</td>\n",
       "      <td>97701.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Pizza Place</td>\n",
       "      <td>Bianca Pizza</td>\n",
       "      <td>22.50</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Little Pizza Paradise</td>\n",
       "      <td>Cascade Village Mall Across From Target</td>\n",
       "      <td>Bend</td>\n",
       "      <td>US</td>\n",
       "      <td>97701.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Pizza Place</td>\n",
       "      <td>Cheese Pizza</td>\n",
       "      <td>18.95</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Brentwood</td>\n",
       "      <td>148 S Barrington Ave</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>US</td>\n",
       "      <td>90049.0</td>\n",
       "      <td>Brentwood</td>\n",
       "      <td>American Restaurant,Bar,Bakery</td>\n",
       "      <td>Pizza, Margherita</td>\n",
       "      <td>12.00</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Brentwood</td>\n",
       "      <td>148 S Barrington Ave</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>US</td>\n",
       "      <td>90049.0</td>\n",
       "      <td>Brentwood</td>\n",
       "      <td>American Restaurant,Bar,Bakery</td>\n",
       "      <td>Pizza, Mushroom</td>\n",
       "      <td>13.00</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Brentwood</td>\n",
       "      <td>148 S Barrington Ave</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>US</td>\n",
       "      <td>90049.0</td>\n",
       "      <td>Brentwood</td>\n",
       "      <td>American Restaurant,Bar,Bakery</td>\n",
       "      <td>Pizza, Puttenesca</td>\n",
       "      <td>13.00</td>\n",
       "      <td>USD</td>\n",
       "      <td>Olives, onions, capers, tomatoes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name                                  address  \\\n",
       "0  Little Pizza Paradise  Cascade Village Mall Across From Target   \n",
       "1  Little Pizza Paradise  Cascade Village Mall Across From Target   \n",
       "2          The Brentwood                     148 S Barrington Ave   \n",
       "3          The Brentwood                     148 S Barrington Ave   \n",
       "4          The Brentwood                     148 S Barrington Ave   \n",
       "\n",
       "          city country postcode      state                      categories  \\\n",
       "0         Bend      US  97701.0     Oregon                     Pizza Place   \n",
       "1         Bend      US  97701.0     Oregon                     Pizza Place   \n",
       "2  Los Angeles      US  90049.0  Brentwood  American Restaurant,Bar,Bakery   \n",
       "3  Los Angeles      US  90049.0  Brentwood  American Restaurant,Bar,Bakery   \n",
       "4  Los Angeles      US  90049.0  Brentwood  American Restaurant,Bar,Bakery   \n",
       "\n",
       "           menu item  item value currency                  item description  \n",
       "0       Bianca Pizza       22.50      USD                               NaN  \n",
       "1       Cheese Pizza       18.95      USD                               NaN  \n",
       "2  Pizza, Margherita       12.00      USD                               NaN  \n",
       "3    Pizza, Mushroom       13.00      USD                               NaN  \n",
       "4  Pizza, Puttenesca       13.00      USD  Olives, onions, capers, tomatoes  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Made a dictionary for all states in the dataset with their full names and their abbreviations\n",
    "\n",
    "states = {'AL': 'Alabama', 'AK': 'Alaska', 'AS': 'Arkansas', 'AZ': 'Arizona', 'CA': 'California', 'CO': 'Colorado',\n",
    "         'CT': 'Connecticut', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho', \n",
    "         'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisianna', \n",
    "         'MA': 'Maryland', 'MI': 'Michigan', 'MN': 'Minnesota', 'MO': 'Missouri', 'MS': 'Mississipi', 'MT': 'Montana',\n",
    "         'NV': 'Nevada', 'NE': 'Nebraska', 'NH': 'New_Hampshire', 'NJ': 'New_Jersey', 'NM': 'New_Mexico', \n",
    "         'NY': 'New_York', 'NC': 'North_Carolina', 'ND': 'North_Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma', 'OR': 'Oregon',\n",
    "         'PA': 'Pennsylvania', 'RI': 'Rhode_Island', 'SC': 'South_Carolina', 'SD': 'South_Dakota', 'TX': 'Texas',\n",
    "         'TN': 'Tennessee', 'UT': 'Utah', 'VT': 'Vermont', 'VA': 'Virginia', 'WY': 'Wyoming', 'WI': 'Wisconsin',\n",
    "         'WA': 'Washington', 'WV': 'West_Virginia'}\n",
    "\n",
    "\n",
    "# iterating through the rows in the data to replace abbreviated state names with their full names\n",
    "for idx, row in df.iterrows():\n",
    "    state = row['state']\n",
    "    if state in states:\n",
    "        df.at[idx, 'state'] = states[state]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e24441",
   "metadata": {},
   "source": [
    "Once a dictionary for the name of the states have been created, it is now time to standardize the strings of the columns: name, city, categories, menu item, item description, categories, state and address. This is to remove non-ascii characters and to  introduce uniformity in how entities are stored in the dataframe, they will be in lower case and any space between words will have an underscore replacing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acdb734e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>categories</th>\n",
       "      <th>menu item</th>\n",
       "      <th>item value</th>\n",
       "      <th>currency</th>\n",
       "      <th>item description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>little_pizza_paradise</td>\n",
       "      <td>cascade_village_mall_across_from_target</td>\n",
       "      <td>bend</td>\n",
       "      <td>US</td>\n",
       "      <td>97701.0</td>\n",
       "      <td>oregon</td>\n",
       "      <td>pizza_place</td>\n",
       "      <td>bianca_pizza</td>\n",
       "      <td>22.50</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>little_pizza_paradise</td>\n",
       "      <td>cascade_village_mall_across_from_target</td>\n",
       "      <td>bend</td>\n",
       "      <td>US</td>\n",
       "      <td>97701.0</td>\n",
       "      <td>oregon</td>\n",
       "      <td>pizza_place</td>\n",
       "      <td>cheese_pizza</td>\n",
       "      <td>18.95</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the_brentwood</td>\n",
       "      <td>148_s_barrington_ave</td>\n",
       "      <td>los_angeles</td>\n",
       "      <td>US</td>\n",
       "      <td>90049.0</td>\n",
       "      <td>brentwood</td>\n",
       "      <td>american_restaurant,bar,bakery</td>\n",
       "      <td>pizza,_margherita</td>\n",
       "      <td>12.00</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the_brentwood</td>\n",
       "      <td>148_s_barrington_ave</td>\n",
       "      <td>los_angeles</td>\n",
       "      <td>US</td>\n",
       "      <td>90049.0</td>\n",
       "      <td>brentwood</td>\n",
       "      <td>american_restaurant,bar,bakery</td>\n",
       "      <td>pizza,_mushroom</td>\n",
       "      <td>13.00</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the_brentwood</td>\n",
       "      <td>148_s_barrington_ave</td>\n",
       "      <td>los_angeles</td>\n",
       "      <td>US</td>\n",
       "      <td>90049.0</td>\n",
       "      <td>brentwood</td>\n",
       "      <td>american_restaurant,bar,bakery</td>\n",
       "      <td>pizza,_puttenesca</td>\n",
       "      <td>13.00</td>\n",
       "      <td>USD</td>\n",
       "      <td>olives,_onions,_capers,_tomatoes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name                                  address  \\\n",
       "0  little_pizza_paradise  cascade_village_mall_across_from_target   \n",
       "1  little_pizza_paradise  cascade_village_mall_across_from_target   \n",
       "2          the_brentwood                     148_s_barrington_ave   \n",
       "3          the_brentwood                     148_s_barrington_ave   \n",
       "4          the_brentwood                     148_s_barrington_ave   \n",
       "\n",
       "          city country postcode      state                      categories  \\\n",
       "0         bend      US  97701.0     oregon                     pizza_place   \n",
       "1         bend      US  97701.0     oregon                     pizza_place   \n",
       "2  los_angeles      US  90049.0  brentwood  american_restaurant,bar,bakery   \n",
       "3  los_angeles      US  90049.0  brentwood  american_restaurant,bar,bakery   \n",
       "4  los_angeles      US  90049.0  brentwood  american_restaurant,bar,bakery   \n",
       "\n",
       "           menu item  item value currency                  item description  \n",
       "0       bianca_pizza       22.50      USD                               NaN  \n",
       "1       cheese_pizza       18.95      USD                               NaN  \n",
       "2  pizza,_margherita       12.00      USD                               NaN  \n",
       "3    pizza,_mushroom       13.00      USD                               NaN  \n",
       "4  pizza,_puttenesca       13.00      USD  olives,_onions,_capers,_tomatoes  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"name\",\"city\",\"categories\",\"menu item\",\"item description\",\"categories\",\"state\",'address']\n",
    "for col in columns:\n",
    "    df[col] = df[col].str.lower()\n",
    "    df[col].replace(' ','_',regex = True, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f6cca3",
   "metadata": {},
   "source": [
    "### Subtask RDF.1 and RDF.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ab813c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code idea adapted from Lab 5 solutions at \n",
    "# https://github.com/city-knowledge-graphs/python-2023/blob/main/lab5/solution/lab5_solution.py\n",
    "\n",
    "# Initialize an empty RDF graph\n",
    "g = Graph()\n",
    "\n",
    "# Define a namespace for our RDF data. Here it is set to a URL for the coursework.\n",
    "namespace = \"http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/\"\n",
    "cw = Namespace(namespace)\n",
    "\n",
    "# Bind a prefix, here \"cw\", to the namespace\n",
    "g.bind(\"cw\",cw)\n",
    "\n",
    "# Add a triple to the graph to state the creator of the data. The URI for the namespace itself is used as the subject.\n",
    "g.add((URIRef(namespace), cw.Created_by, Literal('Faiq Komron', datatype = RDFS.Literal)))\n",
    "\n",
    "# Iterate over each row in a pandas dataframe, df\n",
    "for idx, row in df.iterrows():\n",
    "\n",
    "  # Create URIRef objects for each entity involved: the restaurant, the pizza (menu item), the state, and the category\n",
    "  restaurant = URIRef(namespace + row['city'] + \"_\" + row['name'])\n",
    "  pizza = URIRef(namespace + row['name'] + \"_\" + row['menu item'])  \n",
    "  state = URIRef(namespace + row['state'])\n",
    "  category = URIRef(namespace + row['categories'])\n",
    "\n",
    "  # Add RDF.type relations to the graph to define what kind of entity each URI is\n",
    "  g.add((restaurant, RDF.type, cw.Restaurant))\n",
    "  g.add((pizza, RDF.type, cw.Pizza))\n",
    "  g.add((state, RDF.type, cw.State))\n",
    "  g.add((category, RDF.type, cw.Category))\n",
    "\n",
    "  # Add more detailed object properties to the graph, such as which pizzas are served at which restaurants,\n",
    "  # which state the restaurant is in, the menu category for each pizza, and the price of each pizza\n",
    "  g.add((pizza, cw.Served_at, restaurant))\n",
    "  g.add((restaurant, cw.Serves, pizza))\n",
    "  g.add((state, cw.hasName, Literal(row['state'])))\n",
    "  g.add((restaurant, cw.locatedInState, state))\n",
    "  g.add((pizza, cw.hasMenuCategory, category))\n",
    "  g.add((pizza, cw.hasPrice, Literal(row['item value'], datatype=XSD.float)))\n",
    "  g.add((restaurant, cw.hasAddress, Literal(row['address'])))\n",
    "  g.add((restaurant, cw.hasPostcode, Literal(row['postcode'])))\n",
    "\n",
    "  # Add data properties to the graph: the name of the restaurant, the name of the pizza, and the address of the restaurant\n",
    "  g.add((restaurant, cw.Name, Literal(row['name'], datatype = RDFS.Literal)))\n",
    "  g.add((pizza, cw.Name, Literal(row['menu item'], datatype = RDFS.Literal)))\n",
    "  g.add((restaurant, cw.Address, Literal(row['address'], datatype = RDFS.Literal)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7ee6288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of triples are 4053\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of triples are {}\".format(len(g)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cbbb445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing DataFrame. Now serializing graph to file.\n",
      "Finished serializing graph to file.\n"
     ]
    }
   ],
   "source": [
    "print(\"Finished processing DataFrame. Now serializing graph to file.\")\n",
    "\n",
    "g.serialize(destination='populated_graph.ttl', format='turtle') \n",
    "\n",
    "print(\"Finished serializing graph to file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04280031",
   "metadata": {},
   "source": [
    "### Subtask RDF.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7b8b279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.27479674796747966\n"
     ]
    }
   ],
   "source": [
    "# this is to check that isub is working as it should\n",
    "print(isub('hello', 'hello'))  # Should return 1.0 or a very high score close to 1.0\n",
    "print(isub('hello', 'world'))  # Should return 0.0 or a very low score close to 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb3373db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lookup import WikidataAPI, GoogleKGLookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba879c2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "google_kg_namespace = \"https://kgsearch.googleapis.com/v1/entities/\"\n",
    "google = Namespace(google_kg_namespace)\n",
    "g.bind(\"google\", google)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "386564a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the GoogleKGLookup class. This class contains methods to interact with the Google Knowledge Graph API.\n",
    "kg = GoogleKGLookup()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c61fb73",
   "metadata": {},
   "source": [
    "This code is iterating over a DataFrame (which presumably contains data about various restaurants and their locations) and adding this information to an RDF graph. The code uses the Google Knowledge Graph to look up entities for cities, states, and countries and adds them to the graph as well. Essentially, this code is creating a semantic representation of a dataset about restaurants and their locations, using a combination of local data and information retrieved from the Google Knowledge Graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e335d857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing DataFrame\n",
      "Processing row 0\n",
      "Getting entities for city: bend\n",
      "Getting entities for state: oregon\n",
      "Getting entities for country: US\n",
      "Adding triples to graph\n",
      "Processing row 50\n",
      "Getting entities for city: arnold\n",
      "Getting entities for state: missouri\n",
      "Getting entities for country: US\n",
      "Adding triples to graph\n",
      "Processing row 100\n",
      "Getting entities for city: lawrence_township\n",
      "Getting entities for state: lawrenceville\n",
      "Getting entities for country: US\n",
      "Adding triples to graph\n",
      "Processing row 150\n",
      "Getting entities for city: barboursville\n",
      "Getting entities for state: west_virginia\n",
      "Getting entities for country: US\n",
      "Adding triples to graph\n",
      "Processing row 200\n",
      "Getting entities for city: philadelphia\n",
      "Getting entities for state: pennsylvania\n",
      "Getting entities for country: US\n",
      "Adding triples to graph\n",
      "Processing row 250\n",
      "Getting entities for city: suffolk\n",
      "Getting entities for state: virginia\n",
      "Getting entities for country: US\n",
      "Adding triples to graph\n",
      "Processing row 300\n",
      "Getting entities for city: bronson\n",
      "Getting entities for state: michigan\n",
      "Getting entities for country: US\n",
      "Adding triples to graph\n",
      "Processing row 350\n",
      "Getting entities for city: alameda\n",
      "Getting entities for state: california\n",
      "Getting entities for country: US\n",
      "Adding triples to graph\n",
      "Processing row 400\n",
      "Getting entities for city: sioux_city\n",
      "Getting entities for state: iowa\n",
      "Getting entities for country: US\n",
      "Adding triples to graph\n",
      "Processing row 450\n",
      "Getting entities for city: pittsburgh\n",
      "Getting entities for state: pitt\n",
      "Getting entities for country: US\n",
      "Adding triples to graph\n",
      "Processing row 500\n",
      "Getting entities for city: new_york\n",
      "Getting entities for state: manhattan\n",
      "Getting entities for country: US\n",
      "Adding triples to graph\n",
      "Finished processing DataFrame. Now serializing graph to file.\n",
      "Finished serializing graph to file.\n"
     ]
    }
   ],
   "source": [
    "# Print a message indicating the start of the process.\n",
    "print(\"Start processing DataFrame\")\n",
    "\n",
    "# Loop through each row of the DataFrame.\n",
    "for idx, row in df.iterrows():\n",
    "    # To avoid spamming the console, only print status updates every 50 rows.\n",
    "    if idx % 50 == 0:\n",
    "        try:\n",
    "            # Print messages indicating the row number being processed and the city, state, and country entities being retrieved.\n",
    "            print(f\"Processing row {idx}\")\n",
    "            print(f\"Getting entities for city: {row['city']}\")\n",
    "            entities_city = kg.getKGEntities(row['city'], limit=1)\n",
    "            if entities_city: \n",
    "                city = URIRef(entities_city[0].getId()) \n",
    "            else:\n",
    "                city = URIRef(google_kg_namespace+row['city'])\n",
    "            \n",
    "            print(f\"Getting entities for state: {row['state']}\")\n",
    "            entities_state = kg.getKGEntities(row['state'], limit=1)\n",
    "            if entities_state: \n",
    "                state = URIRef(entities_state[0].getId())\n",
    "            else:\n",
    "                state = URIRef(google_kg_namespace+row['state']) \n",
    "            \n",
    "            print(f\"Getting entities for country: {row['country']}\")\n",
    "            entities_country = kg.getKGEntities(row['country'], limit=1)\n",
    "            if entities_country: \n",
    "                country = URIRef(entities_country[0].getId())\n",
    "            else:\n",
    "                country = URIRef(google_kg_namespace+row['country'])\n",
    "            \n",
    "            print(\"Adding triples to graph\")\n",
    "        except Exception as e:\n",
    "            # If an error occurs during the entity retrieval, print the error message.\n",
    "            print(f\"Error occurred: {e}\")\n",
    "\n",
    "    restaurant = URIRef(google_kg_namespace + row['name'])\n",
    "\n",
    "    # Add triples to the graph to define the type of each entity\n",
    "    g.add((city, RDF.type, cw.City))\n",
    "    g.add((state, RDF.type, cw.State))\n",
    "    g.add((country, RDF.type, cw.Country))\n",
    "    \n",
    "    # Add triples to the graph to define the location of the restaurant, and the relationships between cities, states, and countries\n",
    "    g.add((restaurant, cw.locatedInState, state))\n",
    "    g.add((city, cw.locatedInState, state))\n",
    "    g.add((state, cw.locatedInCountry, country))\n",
    "    g.add((country, cw.hasState, state))\n",
    "    g.add((state, cw.hasCity, city))\n",
    "    g.add((city, cw.hasRestaurant, restaurant))\n",
    "    \n",
    "    # Add triples to the graph to define the names of the city, state, and country\n",
    "    g.add((city, cw.Has_name, Literal(row['city'], datatype = RDFS.Literal)))\n",
    "    g.add((state, cw.Has_name, Literal(row['state'], datatype = RDFS.Literal)))\n",
    "    g.add((country, cw.Has_name, Literal(row['country'], datatype = RDFS.Literal)))\n",
    "\n",
    "# Print a message indicating that processing is complete.\n",
    "print(\"Finished processing DataFrame. Now serializing graph to file.\")\n",
    "\n",
    "# Serialize the graph to a file in Turtle format.\n",
    "g.serialize(destination='Google KG output.ttl', format='turtle')\n",
    "\n",
    "# Print a message indicating that the graph has been serialized.\n",
    "print(\"Finished serializing graph to file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c876b98a",
   "metadata": {},
   "source": [
    "After the ontology has been populated with Google KG entities, it is saved in the turtle file \"Google KG output\". Now, we will repeat the same procedure but using Wikidata API and its resources and entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac3a72b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_namespace = \"https://www.wikidata.org/w/api.php\"\n",
    "wiki = Namespace(wikidata_namespace)\n",
    "g.bind(\"wiki\", wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8909f4",
   "metadata": {},
   "source": [
    "In this code, we're creating an instance of a WikidataAPI class, which presumably has a method getKGEntities that takes a keyword, a limit, and a type as input parameters and fetches entities from the Wikidata Knowledge Graph that match the query. The entities retrieved are then printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3a581c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create an instance of the WikidataAPI class. This class contains methods to interact with the Wikidata API.\n",
    "wikidata = WikidataAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7af35a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing DataFrame\n",
      "Processing row 0\n",
      "Getting entities for city: bend\n",
      "Error occurred: 'entities'\n",
      "Processing row 50\n",
      "Getting entities for city: arnold\n",
      "Error occurred: 'entities'\n",
      "Processing row 100\n",
      "Getting entities for city: lawrence_township\n",
      "Error occurred: 'entities'\n",
      "Processing row 150\n",
      "Getting entities for city: barboursville\n",
      "Error occurred: 'entities'\n",
      "Processing row 200\n",
      "Getting entities for city: philadelphia\n",
      "Error occurred: 'entities'\n",
      "Processing row 250\n",
      "Getting entities for city: suffolk\n",
      "Error occurred: 'entities'\n",
      "Processing row 300\n",
      "Getting entities for city: bronson\n",
      "Error occurred: 'entities'\n",
      "Processing row 350\n",
      "Getting entities for city: alameda\n",
      "Error occurred: 'entities'\n",
      "Processing row 400\n",
      "Getting entities for city: sioux_city\n",
      "Error occurred: 'entities'\n",
      "Processing row 450\n",
      "Getting entities for city: pittsburgh\n",
      "Error occurred: 'entities'\n",
      "Processing row 500\n",
      "Getting entities for city: new_york\n",
      "Error occurred: 'entities'\n",
      "Finished processing DataFrame. Now serializing graph to file.\n",
      "Finished serializing graph to file.\n"
     ]
    }
   ],
   "source": [
    "# Print statement to signal the beginning of DataFrame processing\n",
    "print(\"Start processing DataFrame\")\n",
    "\n",
    "# Loop through each row of the DataFrame with its index\n",
    "for idx, row in df.iterrows():\n",
    "\n",
    "    # Print status every 50 rows to monitor progress and avoid spamming the console\n",
    "    if idx % 50 == 0:\n",
    "        try:\n",
    "            # Print messages indicating the row number being processed and the city, state, and country entities being retrieved.\n",
    "            print(f\"Processing row {idx}\")\n",
    "            print(f\"Getting entities for city: {row['city']}\")\n",
    "            entities_city = wikidata.getKGEntities(row['city'], limit=1)\n",
    "            # If city entity is found, create URI with entity ID\n",
    "            # If not, create URI with city name\n",
    "            if entities_city: \n",
    "                city = URIRef(entities_city[0].getId()) \n",
    "            else:\n",
    "                city = URIRef(wikidata_namespace+row['city']) \n",
    "\n",
    "           \n",
    "            print(f\"Getting entities for state: {row['state']}\")\n",
    "            entities_state = wikidata.getKGEntities(row['state'], limit=1)\n",
    "            if entities_state: \n",
    "                state = URIRef(entities_state[0].getId())\n",
    "            else:\n",
    "                state = URIRef(wikidata_namespace+row['state']) \n",
    "\n",
    "            \n",
    "            print(f\"Getting entities for country: {row['country']}\")\n",
    "            entities_country = wikidata.getKGEntities(row['country'], limit=1)\n",
    "            if entities_country: \n",
    "                country = URIRef(entities_country[0].getId())\n",
    "            else:\n",
    "                country = URIRef(wikidata_namespace+row['country'])\n",
    "\n",
    "            print(\"Adding triples to graph\")\n",
    "        except Exception as e:\n",
    "            # Catch any exceptions and print error message\n",
    "            print(f\"Error occurred: {e}\")\n",
    "\n",
    "    # Create URI for restaurant entity\n",
    "    restaurant = URIRef(wikidata_namespace + row['name'])\n",
    "\n",
    "    # Add classes to RDF graph\n",
    "    g.add((city, RDF.type, cw.City))\n",
    "    g.add((state, RDF.type, cw.State))\n",
    "    g.add((country, RDF.type, cw.Country))\n",
    "    \n",
    "    # Add object properties to RDF graph\n",
    "    g.add((restaurant, cw.locatedInState, state))\n",
    "    g.add((city, cw.locatedInState, state))\n",
    "    g.add((state, cw.locatedInCountry, country))\n",
    "    g.add((country, cw.hasState, state))\n",
    "    g.add((state, cw.hasCity, city))\n",
    "    g.add((city, cw.hasRestaurant, restaurant))\n",
    "    \n",
    "    # Add data properties to RDF graph\n",
    "    g.add((city, cw.Has_name, Literal(row['city'], datatype = RDFS.Literal)))\n",
    "    g.add((state, cw.Has_name, Literal(row['state'], datatype = RDFS.Literal)))\n",
    "    g.add((country, cw.Has_name, Literal(row['country'], datatype = RDFS.Literal)))\n",
    "\n",
    "# Serialize the RDF graph to a Turtle file\n",
    "print(\"Finished processing DataFrame. Now serializing graph to file.\")\n",
    "g.serialize(destination='Wikidata output.ttl', format='turtle')\n",
    "print(\"Finished serializing graph to file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a91ead",
   "metadata": {},
   "source": [
    "The results are saved to the Wikidata output file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3da74a3",
   "metadata": {},
   "source": [
    "### Subtask RDF.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "332c4739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of triples after reasoning:  15662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Ne657e7d0776849c799d76e7814366c81 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an instance of an RDF graph\n",
    "g = Graph()\n",
    "\n",
    "# Load cw_onto\n",
    "g.parse('pizza-restaurants-ontology.ttl') \n",
    "\n",
    "# Load populated graph\n",
    "g.parse('populated_graph.ttl')\n",
    "# Apply OWL-RL reasoning to the graph to infer and add new triples\n",
    "owlrl.DeductiveClosure(owlrl.OWLRL_Semantics, axiomatic_triples=True, datatype_axioms=False).expand(g)\n",
    "\n",
    "# Print the number of triples in the graph after the reasoning procedure\n",
    "print(\"number of triples after reasoning: \", len(g))\n",
    "\n",
    "# Serialize the graph and save it to a Turtle file ('populated_with_onto_reasoning.ttl')\n",
    "# The resulting file will contain the data from cw_onto and what was created in RDF.1 and RDF.2\n",
    "# plus the inferred triples from the reasoning process\n",
    "g.serialize(destination = 'populated_with_onto_reasoning.ttl', format = 'ttl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d7778f",
   "metadata": {},
   "source": [
    "##  SPARQL and Reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c707e278",
   "metadata": {},
   "source": [
    "### SPARQL.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d594673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query result written to sparql1.csv file.\n",
      "The max price of a pizza that is below 20 dollars, is 20.0 USD.\n"
     ]
    }
   ],
   "source": [
    "# this query consists of 3 triple patterns and is looking for the maximum price of vegetarian pizzas that are below 20 dollars\n",
    "\n",
    "quer = g.query(\n",
    "\"\"\"    \n",
    "PREFIX cw: <http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "SELECT (MAX(?price) AS ?maxprice) \n",
    "WHERE\n",
    "{\n",
    "?pizza rdf:type cw:Pizza .\n",
    "?pizza cw:hasPrice ?price . \n",
    "FILTER (?price <=20)\n",
    "}\n",
    "\n",
    "\"\"\")\n",
    "with open('sparql1.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Max Price'])\n",
    "    for row in quer:\n",
    "        writer.writerow([round(float(row[0]), 2)])\n",
    "\n",
    "print(\"Query result written to sparql1.csv file.\")\n",
    "\n",
    "# printing result\n",
    "for row in quer:\n",
    "    print(\"The max price of a pizza that is below 20 dollars, is {} USD.\".format(round(float(row.maxprice), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429493c1",
   "metadata": {},
   "source": [
    "### SPARQL.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0b4f48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query result written to sparql2.csv file.\n",
      "The average price of vegeterian pizzas that are above 20 dollars is 31.58 USD.\n"
     ]
    }
   ],
   "source": [
    "# this query uses 3 triple patterns, and is looking for the average price of pizzas that are above $20, using an AVG function\n",
    "quer = g.query(\n",
    "\"\"\"    \n",
    "PREFIX cw: <http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "SELECT (AVG(?price) AS ?avgprice) \n",
    "WHERE\n",
    "{\n",
    "?pizza rdf:type cw:Pizza .\n",
    "?pizza cw:hasPrice ?price .\n",
    "?restaurant cw:Serves ?pizza .\n",
    "FILTER (?price >=20)\n",
    "}\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "with open('sparql2.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Average Price'])\n",
    "    for row in quer:\n",
    "        writer.writerow([round(float(row.avgprice), 2)])\n",
    "        \n",
    "print(\"Query result written to sparql2.csv file.\")\n",
    "\n",
    "for row in quer:\n",
    "    print(\"The average price of vegeterian pizzas that are above 20 dollars is {} USD.\".format(round(float(row.avgprice), 2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b495bc18",
   "metadata": {},
   "source": [
    "### SPARQL.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd947520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/massapequa_park_pizza_bistro\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/white_plains_the_melting_pot_-_white_plains\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/staten_island_mario's_-_staten_island\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/buffalo_brando's_pizza\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/white_plains_euro_pizzeria\n",
      "The result has been saved to sparql3.csv\n"
     ]
    }
   ],
   "source": [
    "# this query looks to see if there are restaurants in LA or NYC that has restaurants which are not named Mcdonalds,\n",
    "# using UNION pattern and Negation\n",
    "quer = g.query(\n",
    "\"\"\"\n",
    "PREFIX cw: <http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "SELECT ?restaurant\n",
    "WHERE {\n",
    "  {\n",
    "    ?restaurant cw:locatedInState ?state .\n",
    "    ?state cw:hasName \"new_york\" .\n",
    "  }\n",
    "  UNION\n",
    "  {\n",
    "    ?restaurant cw:locatedInState ?state .\n",
    "    ?state cw:hasName \"los_angeles\" .\n",
    "  }\n",
    "  FILTER NOT EXISTS {\n",
    "    ?restaurant cw:Name \"Mcdonalds\" .\n",
    "  }\n",
    "}\"\"\")\n",
    "# Save the count result to a CSV file\n",
    "names = []\n",
    "with open('sparql3.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Restaurant Names'])\n",
    "    for row in quer:\n",
    "         writer.writerow([row.restaurant])\n",
    "         print(row.restaurant)\n",
    "        \n",
    "print(\"The result has been saved to sparql3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0879fdd7",
   "metadata": {},
   "source": [
    "### SPARQL.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fcb66de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/illinois\n",
      "7 http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/maryland\n",
      "8 http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/pennsylvania\n",
      "11 http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/california\n",
      "11 http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/texas\n",
      "Results saved to sparql4.csv\n"
     ]
    }
   ],
   "source": [
    "# this query is aggregating and filtering by counting states that have more than 5 restaurants, \n",
    "# and then groups the result by the states\n",
    "quer = g.query(\n",
    "\"\"\"    \n",
    "PREFIX cw: <http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "\n",
    "SELECT (COUNT(DISTINCT ?restaurant) AS ?count) ?state\n",
    "WHERE\n",
    "{\n",
    "?restaurant cw:locatedInState ?state .\n",
    "?state rdf:type cw:State .\n",
    "}\n",
    "GROUP BY ?state\n",
    "HAVING(COUNT(?restaurant) >5)\n",
    "\"\"\")\n",
    "\n",
    "for row in quer:\n",
    "  print(row[0], row[1])\n",
    "# open file for writing\n",
    "with open('sparql4.csv', 'w', newline='') as file:\n",
    "\n",
    "    # create CSV writer\n",
    "    writer = csv.writer(file)\n",
    "    # write header row\n",
    "    writer.writerow(['Restaurant Count', 'state'])\n",
    "    # loop over query results and write rows to CSV file\n",
    "    for row in quer:\n",
    "        writer.writerow([row[0], row[1]])\n",
    "        \n",
    "print(\"Results saved to sparql4.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34a9825",
   "metadata": {},
   "source": [
    "### SPARQL.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfaa2115",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/american_restaurant_and_asian_restaurant 6 6.740000000000001\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/pizza_place,restaurants,food_&_entertainment 7 10.39\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/american_restaurant,_pizza_place,_and_gluten-free_restaurant,american_restaurant,pizza_place,gluten-free_restaurant 8 nan\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/pizza,restaurants 8 10.3025\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/italian_restaurant,pizza_place,take_out_restaurants,restaurants,italian_restaurant_and_pizza_place,pizza,doctor 9 8.501111111111111\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/pizza_place,pizza,sandwich_shops,italian_restaurants,delicatessens,restaurants 9 nan\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/burger_joint_and_cupcake_shop 9 17.06111111111111\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/pizza,caterers,take_out_restaurants,family_style_restaurants,restaurants,catering,pizza_place 9 17.191111111111113\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/deli_/_bodega,mediterranean_restaurants,american_restaurants,deli_/_bodega_south_philadelphia,caterers,restaurants,sandwich_shops,bagels,italian_restaurants,delicatessens,health_food_restaurants 10 4.415000000000001\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/italian_restaurant 11 8.859090909090908\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/pizza_place,sacramento_restaurants 11 11.568181818181818\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/restaurant,italian_restaurant 11 13.454545454545455\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/pizza_place,_bar,_and_sports_bar_lodo,american_restaurant,coffee_shop_lodo,restaurants,pizza_place,_bar,_and_sports_bar,pizza_place_lodo,bakeries,restaurant,american_restaurant_lodo,bar,dessert_shops,pizza_place,sports_bar,burger_joint,_american_restaurant,_and_fast_food_restaurant_lodo 11 nan\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/italian_restaurant,restaurant 12 18.41\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/american_restaurant,bar 13 nan\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/sports_bar,bar,sports_bar_and_bar,sports_bar_and_bar_east_end 13 nan\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/pizza_place,pizza,restaurants,take_out_restaurants 14 6.756428571428572\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/pizza_place,italian_restaurant,restaurants,pizza_place_and_italian_restaurant 17 15.047058823529408\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/pizza_place,mediterranean_restaurant,take_out_restaurants,caterers,restaurants,pizza 20 nan\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/restaurant 26 nan\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/pizza_place 66 nan\n",
      "Results saved to sparql5.csv\n"
     ]
    }
   ],
   "source": [
    "# the final query is ordered by two conditions that is\n",
    "# ASC(?count) which orders by ascending count alphabetically from A-Z\n",
    "# ?avg price - Then orders ascendingly by average price of the categories\n",
    "# it also aggregates by COUNT over the HAVING filter and groups them by category\n",
    "quer = g.query(\n",
    "\"\"\"    \n",
    "PREFIX cw: <http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "\n",
    "SELECT ?category (COUNT(?pizza) AS ?count) (AVG(?price) AS ?avgPrice)\n",
    "WHERE\n",
    "{\n",
    "?pizza cw:hasMenuCategory ?category .\n",
    "?pizza cw:hasPrice ?price .\n",
    "}\n",
    "GROUP BY ?category\n",
    "HAVING(COUNT(?category) >5)\n",
    "ORDER BY ASC(?count) ASC(?avgPrice)\n",
    "\"\"\")\n",
    "\n",
    "for row in quer:\n",
    "  print(row[0], row[1], row[2])\n",
    "# open file for writing\n",
    "with open('sparql5.csv', 'w', newline='') as file:\n",
    "\n",
    "    # create CSV writer\n",
    "    writer = csv.writer(file)\n",
    "    # write header row\n",
    "    writer.writerow(['Category', 'Count', 'Average Price'])\n",
    "    # loop over query results and write rows to CSV file\n",
    "    for row in quer:\n",
    "        writer.writerow([row[0], row[1], row[2]])\n",
    "        \n",
    "print(\"Results saved to sparql5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db768603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some NAN results appear in average price, \n",
    "# but that's due to missing values or non-integers \n",
    "# in some entries, but it sorts primarily according to the alphabetical order\n",
    "# of the categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03f7672",
   "metadata": {},
   "source": [
    "## Ontology Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71b88d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n"
     ]
    }
   ],
   "source": [
    "from owlready2 import *\n",
    "#Shoudl be imported after owlready\n",
    "from rdflib import Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e74b71f",
   "metadata": {},
   "source": [
    "### Subtask 0A.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4645ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these methods are from lab 7's github at\n",
    "# https://github.com/city-knowledge-graphs/python-2023/blob/main/lab7/lab7_notebook.ipynb\n",
    "# some will be used to perform the tasks required\n",
    "def getClasses(onto):        \n",
    "    return onto.classes()\n",
    "    \n",
    "def getDataProperties(onto):        \n",
    "    return onto.data_properties()\n",
    "    \n",
    "def getObjectProperties(onto):        \n",
    "    return onto.object_properties()\n",
    "    \n",
    "def getIndividuals(onto):    \n",
    "    return onto.individuals()\n",
    "\n",
    "\n",
    "def getRDFSLabelsForEntity(entity):\n",
    "    #if hasattr(entity, \"label\"):\n",
    "    return entity.label\n",
    "\n",
    "\n",
    "def getRDFSLabelsForEntity(entity):\n",
    "    #if hasattr(entity, \"label\"):\n",
    "    return entity.label "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdc6f48",
   "metadata": {},
   "source": [
    "Here we use the getClasses method to print out the classes that exist in both ontologies, this is so we can get a brief overview of how many classes that are in the 2 ontologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d74d761c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes in Ontology: 100\n",
      "http://www.co-ode.org/ontologies/pizza/pizza.owl#Pizza\n",
      "\tPizza\n",
      "\t[locstr('Pizza', 'en')]\n",
      "http://www.co-ode.org/ontologies/pizza/pizza.owl#PizzaBase\n",
      "\tPizzaBase\n",
      "\t[locstr('BaseDaPizza', 'pt'), locstr('PizzaBase', 'en')]\n",
      "http://www.co-ode.org/ontologies/pizza/pizza.owl#Food\n",
      "\tFood\n",
      "\t[locstr('Food', 'en')]\n",
      "http://www.co-ode.org/ontologies/pizza/pizza.owl#Spiciness\n",
      "\tSpiciness\n",
      "\t[locstr('Spiciness', 'en'), locstr('Tempero', 'pt')]\n",
      "http://www.co-ode.org/ontologies/pizza#FoodTopping\n",
      "\tFoodTopping\n",
      "\t[]\n"
     ]
    }
   ],
   "source": [
    "# Methods and solutions are adapted from the lab 7 solutions at Ernesto's github\n",
    "# at https://github.com/city-knowledge-graphs/python-2023/blob/main/lab7/lab7_notebook.ipynb\n",
    "\n",
    "onto=\"pizza.owl\"\n",
    "\n",
    "#Method from owlready\n",
    "onto = get_ontology(onto).load()\n",
    "    \n",
    "print(\"Classes in Ontology: \" + str(len(list(getClasses(onto)))))\n",
    "i=0\n",
    "for cls in getClasses(onto):\n",
    "    i+=1\n",
    "    #Name of entity in URI. But in some cases it may be a \n",
    "    #code like in mouse and human anatomy ontologies                \n",
    "    print(cls.iri)\n",
    "    print(\"\\t\"+cls.name)  \n",
    "    #Labels from RDFS label\n",
    "    print(\"\\t\"+str(getRDFSLabelsForEntity(cls)))\n",
    "    \n",
    "    if i==5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49ea5602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes in Ontology: 151\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants#ItemValue\n",
      "\tItemValue\n",
      "\t['Item value']\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants#Currency\n",
      "\tCurrency\n",
      "\t['Currency']\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants#Address\n",
      "\tAddress\n",
      "\t['Address']\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants#City\n",
      "\tCity\n",
      "\t['City']\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants#Location\n",
      "\tLocation\n",
      "\t['Location']\n"
     ]
    }
   ],
   "source": [
    "cw_onto=\"pizza-restaurants-ontology.owl\"\n",
    "\n",
    "#Method from owlready\n",
    "cw_onto = get_ontology(cw_onto).load()\n",
    "    \n",
    "print(\"Classes in Ontology: \" + str(len(list(getClasses(cw_onto)))))\n",
    "i=0\n",
    "for cls in getClasses(cw_onto):\n",
    "    i+=1\n",
    "    #Name of entity in URI. But in some cases it may be a \n",
    "    #code like in mouse and human anatomy ontologies                \n",
    "    print(cls.iri)\n",
    "    print(\"\\t\"+cls.name)  \n",
    "    #Labels from RDFS label\n",
    "    print(\"\\t\"+str(getRDFSLabelsForEntity(cls)))\n",
    "    \n",
    "    if i==5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ce352e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all classes from the pizza ontology\n",
    "pizza_classes = getClasses(onto) \n",
    "# Retrieve all classes from the cw ontology\n",
    "cw_classes = getClasses(cw_onto)\n",
    "\n",
    "# Retrieve all object properties from the pizza ontology\n",
    "pizza_objectproperties = getObjectProperties(onto)\n",
    "# Retrieve all object properties from the cw ontology\n",
    "cw_objectproperties = getObjectProperties(cw_onto)\n",
    "\n",
    "# Retrieve all data properties from the pizza ontology\n",
    "pizza_dataproperties = getDataProperties(onto)\n",
    "# Retrieve all data properties from the cw ontology\n",
    "cw_dataproperties = getDataProperties(cw_onto)\n",
    "\n",
    "# Retrieve all individuals from the pizza ontology\n",
    "pizza_individuals = getIndividuals(onto)\n",
    "# Retrieve all individuals from the cw ontology\n",
    "cw_individuals = getIndividuals(cw_onto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2dfaaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes in Pizza ontology: 100\n",
      "Number of classes in CW ontology: 151\n",
      "Number of object properties in Pizza ontology: 8\n",
      "Number of object properties in CW ontology: 17\n",
      "Number of data properties in Pizza ontology: 0\n",
      "Number of data properties in CW ontology: 6\n",
      "Number of individuals in Pizza ontology: 5\n",
      "Number of individuals in CW ontology: 0\n"
     ]
    }
   ],
   "source": [
    "pizza_classes = list(getClasses(onto))\n",
    "cw_classes = list(getClasses(cw_onto))\n",
    "print(\"Number of classes in Pizza ontology:\", len(pizza_classes))\n",
    "print(\"Number of classes in CW ontology:\", len(cw_classes))\n",
    "\n",
    "pizza_objectproperties = list(getObjectProperties(onto))\n",
    "cw_objectproperties = list(getObjectProperties(cw_onto))\n",
    "print(\"Number of object properties in Pizza ontology:\", len(pizza_objectproperties))\n",
    "print(\"Number of object properties in CW ontology:\", len(cw_objectproperties))\n",
    "\n",
    "pizza_dataproperties = list(getDataProperties(onto))\n",
    "cw_dataproperties = list(getDataProperties(cw_onto))\n",
    "print(\"Number of data properties in Pizza ontology:\", len(pizza_dataproperties))\n",
    "print(\"Number of data properties in CW ontology:\", len(cw_dataproperties))\n",
    "\n",
    "pizza_individuals = list(getIndividuals(onto))\n",
    "cw_individuals = list(getIndividuals(cw_onto))\n",
    "print(\"Number of individuals in Pizza ontology:\", len(pizza_individuals))\n",
    "print(\"Number of individuals in CW ontology:\", len(cw_individuals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd122d8f",
   "metadata": {},
   "source": [
    "After printing out the number of entities in both ontologies, we can see that the entities that have the possibility of matching are the classes and object properties, as there exists entities with a count of 0 in CW and Pizza ontology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c8ae900",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched classes: 6\n",
      "Matched object properties: 2\n",
      "Matched data properties: 0\n",
      "Matched individuals: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N64a67b1e70be40e79167781bd2c95787 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdflib import Graph, URIRef\n",
    "from rdflib.namespace import OWL\n",
    "\n",
    "# Initialize RDF graph and bind namespaces\n",
    "g = Graph()\n",
    "\n",
    "pizza_ns = \"http://www.co-ode.org/ontologies/pizza/pizza.owl#\"\n",
    "cw_ns = \"http://www.semanticweb.org/city/in3067-inm713/2023/restaurants#\"\n",
    "\n",
    "g.bind(\"pizza\", pizza_ns)\n",
    "g.bind(\"cw\", cw_ns)\n",
    "\n",
    "# Initialize counters for matched entities\n",
    "matched_classes = 0\n",
    "matched_object_properties = 0\n",
    "matched_data_properties = 0\n",
    "matched_individuals = 0\n",
    "\n",
    "# Loop through all classes in the pizza ontology\n",
    "for p_class in pizza_classes:\n",
    "    # For each class in the pizza ontology, loop through all classes in the cw ontology\n",
    "    for c_class in cw_classes:\n",
    "        # Extract the class name from the full IRI for both ontologies\n",
    "        pizza_name = p_class.iri.replace(pizza_ns, \"\")\n",
    "        cw_name = c_class.iri.replace(cw_ns, \"\")\n",
    "\n",
    "        # If the class names match, add an equivalence triple to the graph\n",
    "        if pizza_name == cw_name:\n",
    "            matched_classes += 1\n",
    "            subject = URIRef(f\"{pizza_ns}{pizza_name}\")\n",
    "            predicate = OWL.equivalentClass\n",
    "            obj = URIRef(f\"{cw_ns}{cw_name}\")\n",
    "            g.add((subject, predicate, obj))\n",
    "\n",
    "# Loop through all object properties in the pizza ontology\n",
    "for p_prop in pizza_objectproperties:\n",
    "    # For each object property in the pizza ontology, loop through all object properties in the cw ontology\n",
    "    for c_prop in cw_objectproperties:\n",
    "        # Extract the property name from the full IRI for both ontologies\n",
    "        pizza_prop_name = p_prop.iri.replace(pizza_ns, \"\")\n",
    "        cw_prop_name = c_prop.iri.replace(cw_ns, \"\")\n",
    "\n",
    "        # If the property names match, add an equivalence triple to the graph\n",
    "        if pizza_prop_name == cw_prop_name:\n",
    "            matched_object_properties += 1\n",
    "            subject = URIRef(f\"{pizza_ns}{pizza_prop_name}\")\n",
    "            predicate = OWL.equivalentProperty\n",
    "            obj = URIRef(f\"{cw_ns}{cw_prop_name}\")\n",
    "            g.add((subject, predicate, obj))\n",
    "\n",
    "# Loop through all data properties in the pizza ontology\n",
    "for p_data_prop in pizza_dataproperties:\n",
    "    # For each data property in the pizza ontology, loop through all data properties in the cw ontology\n",
    "    for c_data_prop in cw_dataproperties:\n",
    "        # Extract the data property name from the full IRI for both ontologies\n",
    "        pizza_data_prop_name = p_data_prop.iri.replace(pizza_ns, \"\")\n",
    "        cw_data_prop_name = c_data_prop.iri.replace(cw_ns, \"\")\n",
    "\n",
    "        # If the data property names match, add an equivalence triple to the graph\n",
    "        if pizza_data_prop_name == cw_data_prop_name:\n",
    "            matched_data_properties += 1\n",
    "            subject = URIRef(f\"{pizza_ns}{pizza_data_prop_name}\")\n",
    "            predicate = OWL.equivalentProperty\n",
    "            obj = URIRef(f\"{cw_ns}{cw_data_prop_name}\")\n",
    "            g.add((subject, predicate, obj))\n",
    "\n",
    "# Loop through all individuals in the pizza ontology\n",
    "for p_ind in pizza_individuals:\n",
    "    # For each individual in the pizza ontology, loop through all individuals in the cw ontology\n",
    "    for c_ind in cw_individuals:\n",
    "        # Extract the individual name from the full IRI for both ontologies\n",
    "        pizza_ind_name = p_ind.iri.replace(pizza_ns, \"\")\n",
    "        cw_ind_name = c_ind.iri.replace(cw_ns, \"\")\n",
    "\n",
    "        # If the individual names match, add a sameAs triple to the graph\n",
    "        if pizza_ind_name == cw_ind_name:\n",
    "            matched_individuals += 1\n",
    "            subject = URIRef(f\"{pizza_ns}{pizza_ind_name}\")\n",
    "            predicate = OWL.sameAs\n",
    "            obj = URIRef(f\"{cw_ns}{cw_ind_name}\")\n",
    "            g.add((subject, predicate, obj))\n",
    "\n",
    "# Print the number of matched entities\n",
    "print(f\"Matched classes: {matched_classes}\")\n",
    "print(f\"Matched object properties: {matched_object_properties}\")\n",
    "print(f\"Matched data properties: {matched_data_properties}\")\n",
    "print(f\"Matched individuals: {matched_individuals}\")\n",
    "\n",
    "# Serialize the graph to a Turtle file (if needed)\n",
    "g.serialize(destination=\"OA1.ttl\", format=\"turtle\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4f48cd",
   "metadata": {},
   "source": [
    "After finding the matched entities, they are saved in equivalences.ttl file. We see that there are only 8 entities that match between the 2 ontologies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eaf947",
   "metadata": {},
   "source": [
    "### Subtask OA.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989f19e6",
   "metadata": {},
   "source": [
    "### Subtask OA.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "054fb121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triples after reasoning: 35108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N92cddf4b4885481cb74022ac7a83a092 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create graph \n",
    "g = Graph()\n",
    "\n",
    "# Load cw_onto\n",
    "g.parse('pizza-restaurants-ontology.ttl')\n",
    "\n",
    "# Load pizza.owl ontology\n",
    "g.parse('pizza.owl') \n",
    "\n",
    "# Load alignments\n",
    "g.parse('OA1.ttl')\n",
    "\n",
    "# Load populated data\n",
    "g.parse('populated_with_onto_reasoning.ttl')\n",
    "\n",
    "# Perform reasoning on all of them \n",
    "owlrl.DeductiveClosure(owlrl.OWLRL_Semantics).expand(g)\n",
    "\n",
    "# Print triples after reasoning \n",
    "print(\"Triples after reasoning:\", len(g))\n",
    "\n",
    "# Serialize reasoned graph\n",
    "g.serialize(destination='OA3.ttl', format='ttl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4250f027",
   "metadata": {},
   "source": [
    "### Subtask OA.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7135ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/fresno_valley_lahvosh_baking http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/california\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/irvine_zpizza http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/california\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/laguna_niguel_i_love_bagels http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/california\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/san_diego_tilted_kilt_mission_valley http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/california\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/san_jose_buca_di_beppo_-_san_jose_-_oakridge http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/california\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/santa_cruz_ristorante_italiano http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/california\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/tracy_applebee's_tracy http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/california\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/hermosa_beach_patrick_molloy's_sports_pub http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/california\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/menifee_giovanni's_pizza_and_pasta http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/california\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/sacramento_milanos_pizza http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/california\n",
      "http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/alameda_the_fire_den http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/california\n",
      "Results written to OA4.csv.csv\n"
     ]
    }
   ],
   "source": [
    "quer = g.query(\n",
    "    \"\"\"\n",
    "    PREFIX cw: <http://www.semanticweb.org/city/in3067-inm713/2023/restaurants/>\n",
    "    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
    "\n",
    "    SELECT ?restaurant ?state\n",
    "    WHERE {\n",
    "      ?restaurant a cw:Restaurant .\n",
    "      ?restaurant cw:locatedInState ?state .\n",
    "      FILTER(?state = cw:california) .\n",
    "    }\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "for row in quer:\n",
    "  print(row[0], row[1])\n",
    "\n",
    "# Open CSV file for writing \n",
    "with open('OA4.csv', 'w', newline='') as file:\n",
    "\n",
    "  # Create CSV writer\n",
    "  writer = csv.writer(file)\n",
    "\n",
    "  # Write header row\n",
    "  writer.writerow(['Restaurant', 'State'])\n",
    "\n",
    "  # Loop over results and write to rows\n",
    "  for row in quer:\n",
    "    writer.writerow([row.restaurant, row.state])\n",
    "\n",
    "print(\"Results written to OA4.csv.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d3c29c",
   "metadata": {},
   "source": [
    "## Ontology Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407731fe",
   "metadata": {},
   "source": [
    "### Vector.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6a3eed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not done so already, run this to unzip the owl2vec_star.zip file, if already done, this cell can be deleted or commented,\n",
    "# if the file has not been unzipped, simply uncomment the lines below\n",
    "\n",
    "#import zipfile\n",
    "\n",
    "#zip_file = zipfile.ZipFile('owl2vec_star.zip', 'r')\n",
    "#zip_file.extractall()\n",
    "#zip_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6d393bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N853f0e254a2144bcbed4cff86254d06a (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdflib import Graph\n",
    "g = Graph()\n",
    "g.parse(\"populated_graph.ttl\") \n",
    "g.parse(\"pizza-restaurants-ontology.ttl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834df85d",
   "metadata": {},
   "source": [
    "As the tip suggested combining cw_onto and the generated data into one file, this is what we did to perform the first task of ontology alignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ecaf24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"combined.owl\", \"wb\") as f:\n",
    "    g.serialize(f, format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a26f352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\faiqh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from owl2vec_star import owl2vec_star"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d702b9",
   "metadata": {},
   "source": [
    "For the first configuration in default.cfg, they are: URI_Doc = yes\n",
    "Lit_Doc = yes\n",
    "Mix_Doc = no\n",
    "\n",
    "\n",
    "For the second configuration in default2.cfg, they are: URI_Doc = no\n",
    "Lit_Doc = no\n",
    "Mix_Doc = yes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd953867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters:\n",
    "# ontology_file\n",
    "# config_file\n",
    "# uri_doc\n",
    "# lit_doc\n",
    "# mix_doc\n",
    "gensim_model = owl2vec_star.extract_owl2vec_model(\"combined.owl\", \"./default.cfg\", True, True, True)\n",
    "\n",
    "output_folder=\"alignment_output/\"\n",
    "\n",
    "#results are saved in binary and text format\n",
    "gensim_model.save(output_folder+\"ontology.embeddings\")\n",
    "gensim_model.wv.save_word2vec_format(output_folder+\"ontology.embeddings.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91e6632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_model = owl2vec_star.extract_owl2vec_model(\"combined.owl\", \"./default2.cfg\", True, True, True)\n",
    "\n",
    "output_folder=\"alignment_output/\"\n",
    "\n",
    "#results are saved in binary and text format\n",
    "gensim_model.save(output_folder+\"ontology2.embeddings\")\n",
    "gensim_model.wv.save_word2vec_format(output_folder+\"ontology2.embeddings.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d23527c",
   "metadata": {},
   "source": [
    "The generated vectors are saved in binary and text forms as ontology.embeddings, ontology.txt and ontology2.embeddings, ontology2.txt respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a907f083",
   "metadata": {},
   "source": [
    "### Vector2.1 and Vector2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86d4c8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# Train model 1  \n",
    "model1 = owl2vec_star.extract_owl2vec_model(\"combined.owl\", \"default.cfg\",True, True, True) \n",
    "model1.save(\"model1.embeddings\")\n",
    "\n",
    "# Train model 2\n",
    "model2 = owl2vec_star.extract_owl2vec_model(\"combined.owl\", \"default2.cfg\", True, True, True) \n",
    "model2.save(\"model2.embeddings\")\n",
    "\n",
    "# Load model 1 and checking if configurations are followed\n",
    "m1 = KeyedVectors.load(\"model1.embeddings\")\n",
    "print(model1.vector_size)\n",
    "# Load model 2 and checking if configurations are followed\n",
    "m2 = KeyedVectors.load(\"model2.embeddings\")\n",
    "print(model2.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6154d328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity for ('Pizza', 'Pizza'): \n",
      "Config 1: 1.0000\n",
      "Config 2: 1.0000\n",
      "Similarity for ('restaurant', 'city'): \n",
      "Config 1: 0.6916\n",
      "Config 2: 0.6628\n",
      "Similarity for ('state', 'city'): \n",
      "Config 1: 0.9089\n",
      "Config 2: 0.9100\n",
      "Similarity for ('Pizza', 'food'): \n",
      "Config 1: 0.6639\n",
      "Config 2: 0.6971\n",
      "Similarity for ('restaurant', 'currency'): \n",
      "Config 1: 0.6396\n",
      "Config 2: 0.6236\n",
      "Similarity for ('oregon', 'washington'): \n",
      "Config 1: 0.9911\n",
      "Config 2: 0.9632\n",
      "Analysis:\n",
      "Config 1 has higher similarity for related pairs like Oregon-Washington\n",
      "Config 2 has lower similarity for unrelated pairs like restaurant-currency\n"
     ]
    }
   ],
   "source": [
    "# this solution was adapted from lab 8's notebook on embeddings at \n",
    "# https://github.com/city-knowledge-graphs/python-2023/tree/main/lab8\n",
    "# Load the embeddings from the file \"model1.embeddings\" into a KeyedVectors object\n",
    "m1 = KeyedVectors.load(\"model1.embeddings\") \n",
    "# Extract the word vectors from model1\n",
    "wv1 = m1.wv\n",
    "\n",
    "m2 = KeyedVectors.load(\"model2.embeddings\")\n",
    "# Load the embeddings from the file \"model2.embeddings\" into another KeyedVectors object\n",
    "wv2 = m2.wv\n",
    "# Extract the word vectors from model2\n",
    "\n",
    "# Calculate similarity for each pair\n",
    "# Select entity pairs\n",
    "pairs = [\n",
    "    ('Pizza', 'Pizza'),  \n",
    "    (\"restaurant\", \"city\"),\n",
    "    ('state','city'),\n",
    "    ('Pizza','food'),\n",
    "    ('restaurant','currency'),\n",
    "    ('oregon','washington')\n",
    "]\n",
    "\n",
    "# Calculate similarity for each pair\n",
    "for p in pairs:\n",
    "    sim1 = wv1.similarity(p[0], p[1])  \n",
    "    sim2 = wv2.similarity(p[0], p[1])\n",
    "    \n",
    "    print(\"Similarity for {}: \".format(p))\n",
    "    print(\"Config 1: {:.4f}\".format(sim1))   \n",
    "    print(\"Config 2: {:.4f}\".format(sim2))\n",
    "\n",
    "# Compare observations \n",
    "print(\"Analysis:\")\n",
    "print(\"Config 1 has higher similarity for related pairs like Oregon-Washington\") \n",
    "print(\"Config 2 has lower similarity for unrelated pairs like restaurant-currency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69cfc05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
